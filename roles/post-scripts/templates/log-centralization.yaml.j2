---
apiVersion: v1
kind: Namespace
metadata:
  name: supervision
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit
  namespace: supervision
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluent-bit
rules:
- apiGroups: [""]
  resources:
    - namespaces
    - pods
    - nodes
    - nodes/proxy
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit
subjects:
- kind: ServiceAccount
  name: fluent-bit
  namespace: supervision
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: supervision
  labels:
    k8s-app: fluent-bit
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE input-kubernetes.conf
    @INCLUDE output-loki.conf

  input-kubernetes.conf: |
    [INPUT]
        Name              tail
        Path              /var/log/kubernetes/kube-apiserver.log
        Tag               kube-apiserver
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Parser            kube
    [INPUT]
        Name              tail
        Path              /var/log/kubernetes/kube-scheduler.log
        Tag               kube-scheduler
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Parser            kube
    [INPUT]
        Name              tail
        Path              /var/log/kubernetes/kube-controller-manager.log
        Tag               kube-controller-manager
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Parser            kube
    [INPUT]
        Name              tail
        Path              /var/log/kubernetes/kubelet.log
        Tag               kubelet
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Parser            kube
    [INPUT]
        Name              tail
        Path              /var/log/kubernetes/kube-proxy.log
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Tag               kube-proxy
        Skip_Long_Lines   On
        Parser            kube
    [INPUT]
        Name              tail
        Path              /var/log/etcd.log
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     50MB
        Tag               etcd
        Skip_Long_Lines   On
        Parser            etcd
    [FILTER]
        Name record_modifier
        Match etcd
        Record service etcd
        Record hostname ${HOSTNAME}
    [FILTER]
        Name record_modifier
        Match kube-apiserver
        Record service kube-apiserver
        Record hostname ${HOSTNAME}
    [FILTER]
        Name record_modifier
        Match kube-scheduler
        Record service kube-scheduler
        Record hostname ${HOSTNAME}
    [FILTER]
        Name record_modifier
        Match kube-controller-manager
        Record service kube-controller-manager
        Record hostname ${HOSTNAME}
    [FILTER]
        Name record_modifier
        Match kubelet
        Record service kubelet
        Record hostname ${HOSTNAME}
    [FILTER]
        Name record_modifier
        Match kube-proxy
        Record service kube-proxy
        Record hostname ${HOSTNAME}
  parsers.conf: |
    [PARSER]
        Name        kube
        Format      regex
        Regex       ^(?<level>[^ ]*) (?<time>[^ ]*)     (?<number>[^ ]*) (?<message>[^ ].*)
        Time_Key    time
        Time_Format %H:%M:%S.%L

  output-loki.conf : |
    [OUTPUT]
        Name                   loki
        Match                  etcd
        host                   loki
        tenant_id              kubernetes
        auto_kubernetes_labels off
        line_format            json
        labels                 job=etcd

    [OUTPUT]
        Name                   loki
        Match                  kube-*
        host                   loki
        tenant_id              kubernetes
        auto_kubernetes_labels off
        line_format            json
        labels                 job=kubernetes

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: supervision
  labels:
    k8s-app: fluent-bit-logging
    version: v1
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: fluent-bit-logging
  template:
    metadata:
      labels:
        k8s-app: fluent-bit-logging
        version: v1
        kubernetes.io/cluster-service: "true"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "2020"
        prometheus.io/path: /api/v1/metrics/prometheus
    spec:
      serviceAccountName: fluent-bit
      tolerations:
        - effect: NoSchedule
          operator: Exists
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: fluent-bit
        image: grafana/fluent-bit-plugin-loki:main
        ports:
          - containerPort: 2020
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-config
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: supervision
  labels:
    app: loki
spec:
  type: ClusterIP
  selector:
    app: loki
  ports:
  - name: loki-http
    port: 3100
    # Add protocol
    protocol: TCP
    targetPort: 3100
{% if agorakube_features.supervision.logging.persistent.enabled | bool == True %}
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-data
  namespace: supervision
  labels:
    openebs.io/target-affinity: agorakube-loki-data
spec:
{% if agorakube_features.supervision.logging.persistent.storage.type == "hostpath" %}
  storageClassName: persistent-loki-hostpath
{% endif %}
{% if agorakube_features.supervision.logging.persistent.storage.type == "storageclass" %}
  storageClassName: "{{ agorakube_features.supervision.logging.persistent.storage.storageclass.name }}"
{% endif %}
{% if agorakube_features.supervision.logging.persistent.storage.type == "persistentvolume" %}
  storageClassName: "{{ agorakube_features.supervision.logging.persistent.storage.persistentvolume.name }}"
{% endif %}
  resources:
    requests:
      storage: "{{ agorakube_features.supervision.logging.persistent.storage.capacity }}"
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
{% endif %}
---
# Add PV for Loki
{% if agorakube_features.supervision.logging.persistent.storage.type == "hostpath" %}
apiVersion: v1
kind: PersistentVolume
metadata:
  name: persistent-loki-hostpath
  namespace: supervision
spec:
  storageClassName: persistent-loki-hostpath
  capacity:
    storage: {{ agorakube_features.supervision.logging.persistent.storage.capacity }}
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "{{ agorakube_features.supervision.logging.persistent.storage.hostpath.path }}"
{% endif %}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: supervision
  labels:
    app: loki
spec:
  selector:
    matchLabels:
      app: loki
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: loki
{% if agorakube_features.supervision.logging.persistent.enabled | bool == True  %}
        openebs.io/target-affinity: agorakube-loki-data
{% endif %}
    spec:
#      securityContext:
#        runAsUser: 1000
#        runAsGroup: 3000
#        fsGroup: 2000
      containers:
      - name: loki
        image: grafana/loki:2.4.2
        args:
          - -config.file=/etc/loki/config.yaml
          - -log.level=warn
          - -print-config-stderr=true
          - -target=all
        ports:
        - containerPort: 3100
          # Add protocol
          name: http
          protocol: TCP
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
{% if agorakube_features.supervision.logging.persistent.enabled | bool == True %}
        - name: loki-data
          mountPath: /loki
{% endif %}
      initContainers:
{% if agorakube_features.supervision.dashboard.persistent.enabled | bool == True %}
      - name: chmod-grafana-data
        image: busybox:1.32.0
        command: ['sh', '-c', "chmod -R 777 /loki"]
        volumeMounts:
        - name: loki-data
          mountPath: /loki
{% endif %}
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
{% if agorakube_features.supervision.logging.persistent.enabled | bool == True %}
      - name: loki-data
        persistentVolumeClaim:
          claimName: loki-data
{% endif %}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: supervision
data:
  config.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      wal:
        enabled: true
        dir: /loki/wal
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      chunk_idle_period: 1h       # Any chunk not receiving new logs in this time will be flushed
      max_chunk_age: 1h           # All chunks will be flushed when they hit this age, default is 1h
      chunk_target_size: 1048576  # Loki will attempt to build chunks up to 1.5MB, flushing first if chunk_idle_period or max_chunk_age is reached first
      chunk_retain_period: 30s    # Must be greater than index read cache TTL if using an index cache (Default index read cache TTL is 5m)
      max_transfer_retries: 0     # Chunk transfers disabled

    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks

    compactor:
      working_directory: /loki/boltdb-shipper-compactor
      shared_store: filesystem

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      unordered_writes: true

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s
